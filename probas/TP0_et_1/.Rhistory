mu <- 1
sigma <- 3
nb.tirages <- 100
x.simu <- rnorm(n=nb.tirages, mean=mu, sd=sigma) # simulation
# Quartiles empiriques/expérimentaux calculés sur l'échantillon simulé
# et quantiles théoriques
q4.hat <- quantile(x.simu, probas=c(0.25,0.5,0.75))
print(round(q4.hat,2))
q4.theo <- qnorm(probas, mean=mu, sd=sigma)
q4.theo <- mu + sigma*qnorm(probas, mean=0, sd=1) # variante
print(round(q4.theo,2))
probas <- c(0.025, 0.25, 0.5, 0.75, 0.975)
q <- qnorm(probas, mean=0, sd=1) # quantiles théoriques : "q = quantile"
print(round(q,2))
mu <- 0     # moyenne
sigma <- 1  # écart-type = racine carrée de la variance
nb.tirages <- 100  # nombre de tirages aléatoires = taille échantillon simulé
# Utilisation du générateur de nombre normal rnorm : "r = random" et "norm = normal"
x.simu <- rnorm(n=nb.tirages, mean=mu, sd=sigma)
# Visualisation des données simulées
plot(1:nb.tirages, x.simu, xlab="Numéro de simulation", ylab="Simulations",
main="Simulations d'une loi normale")
abline(h=mu, lty=1, col="red", lwd=2)   # lty = line type (1 par défaut)
abline(h=1.96, lty=2, col="red", lwd=2) # lwd = line width (1 par défaut)
abline(h=-1.96, lty=2, col="red", lwd=2)
# Question 2
# Histogramme : on utilise breaks pour jouer sur le nombre de classes et l'option
# freq = FALSE pour le normaliser (densité de probabilité)
nb.tirages <- 20000
x.simu <- rnorm(n=nb.tirages, mean=mu, sd=sigma)
hist(x.simu, breaks=50, freq=FALSE, xlab="Valeurs simulées", ylab="Densité",
main="",ylim=c(0,0.7))
points(x.simu, rep(0,nb.tirages), pch='+', cex=0.5, col="blue") # cex = coeff. expansion
maxx = mu + 3.5*sigma
minx = mu - 3.5*sigma
x.grid <- seq(minx, maxx, 0.01)
fd <- dnorm(x.grid, mean=mu, sd=sigma) # dnorm pour densité normale : "d = density"
lines(x.grid, fd, col="red", lwd=2)
title("Histogramme et densité réelle")
probas <- c(0.025, 0.25, 0.5, 0.75, 0.975)
q <- qnorm(probas, mean=0, sd=1) # quantiles théoriques : "q = quantile"
print(round(q,2))
nb.tirages <- 20000
x.simu <- rnorm(n=nb.tirages, mean=mu, sd=sigma)
hist(x.simu, breaks=50, freq=FALSE, xlab="Valeurs simulées", ylab="Densité",
main="",ylim=c(0,0.7))
data <- c(1,2,3,4,5,6,7,8,9,10)
quantile(data,0.5)
data <- c(1,2,3,4,5,6,7,8,9,10)
quantile(data,0.1)
data <- c(1,2,3,4,5,6,7,8,9,10)
quantile(data,1)
mu <- 1
sigma <- 3
nb.tirages <- 100
x.simu <- rnorm(n=nb.tirages, mean=mu, sd=sigma) # simulation
# Quartiles empiriques/expérimentaux calculés sur l'échantillon simulé
# et quantiles théoriques
q4.hat <- quantile(x.simu, probas=c(0.25,0.5,0.75))
print(round(q4.hat,2))
q4.theo <- qnorm(probas, mean=mu, sd=sigma)
q4.theo <- mu + sigma*qnorm(probas, mean=0, sd=1) # variante
print(round(q4.theo,2))
q4.hat <- quantile(x.simu, probas=c(0.25,0.5,0.75))
print(round(q4.hat,2))
q4.theo <- qnorm(probas, mean=mu, sd=sigma)
print(round(q4.theo,2))
print(probas)
print(round(q4.hat,2))
q4.theo <- qnorm(probas, mean=mu, sd=sigma)
print(round(q4.theo,2))
q4.theo <- mu + sigma*qnorm(probas, mean=0, sd=1) # variante
print(round(q4.theo,2))
q4.theo <- qnorm(probas, mean=mu, sd=sigma)
print(round(q4.theo,2))
q4.theo1 <- mu + sigma*qnorm(probas, mean=0, sd=1) # variante
print(round(q4.theo1,2))
mu <- 1
sigma <- 3
nb.tirages <- 1000
x.simu <- rnorm(n=nb.tirages, mean=mu, sd=sigma) # simulation
probas <- seq(from=0.05, to=0.95, by=0.05)
q.theo <- qnorm(probas, mean=0, sd=1)
q.hat <- quantile(x.simu, probas)
plot(q.theo, q.hat, xlab="Quantiles théoriques N(0,1)", ylab="Quantiles expérimentaux")
abline(a=mu, b=sigma, col="red", lwd=2)
grid()
title("Droite de Henry")
q.theo <- qnorm(probas, mean=0, sd=1)
print(q.theo)
q.hat <- quantile(x.simu, probas)
print(q.hat)
qqnorm(x.simu); qqline(x.simu, col="red", lwd=2); grid()
probas <- seq(from=0.05, to=0.95, by=0.05)
q.theo <- qnorm(probas, mean=0, sd=1)
print(q.theo)
q.hat <- quantile(x.simu, probas)
print(q.hat)
plot(q.theo, q.hat, xlab="Quantiles théoriques N(0,1)", ylab="Quantiles expérimentaux")
abline(a=mu, b=sigma, col="red", lwd=2)
grid()
title("Droite de Henry")
qqnorm(x.simu); qqline(x.simu, col="red", lwd=2); grid()
qqnorm(x.simu); qqline(x.simu, col="red", lwd=2); grid()
qqnorm(x.simu)
RENAULT_data <- read.csv("RENAULT_2019-09-24.txt", header=T, sep="", dec=".")
setwd("F:/EMSE/3A/BIG Data/probas/TP 2 (sous R) (mercredi 1609)-20200916")
RENAULT_data <- read.csv("RENAULT_2019-09-24.txt", header=T, sep="", dec=".")
View(RENAULT_data)
View(RENAULT_data)
RENAULT_data <- read.csv("RENAULT_2019-09-24.txt", header=T, sep="", dec=".")
# 可以读取csv和txt格式文件 header=T表示从第二行开始读取数据，header=F表示从第一行开始读取数据
#sep是指定分隔符 dec是小数点的表示，默认就是一个点
RENAULT <- RENAULT_data$clot
plot(RENAULT, type='l', ylab = "cours de clôture (en euros)",
xlab="jours boursiers (du 24/09/2018 au 24/09/2019)")
grid()
title("Evolution de l'action RENAULT sur un an")
diff(c(1,2,3,4))
tx_RENAULT <- diff(log(RENAULT)) # diff pour la différence discrète log(S(t)) - log(S(t-1))
plot(100*tx_RENAULT, type='l', ylab="taux en %", xlab="Temps")
abline(h=0, col="red")
title("Taux de rendement logarithmiques action RENAULT sur un an (en %)", cex.main=0.9)
help(mqqnorm)
a <- cblind(c(1,2),c(1,2))
a <- cbind(c(1,2),c(1,2))
a
help(matrice)
help(matrix)
sigma <- matrix(c(1, 0, 1,6,0, 1),nrow = 2)
sigma
sigma <- matrix(c(1, 0, 1,6,0, 1),nrow = 3)
sigma
R0 <- 1200
lbound <- 1.2E+3
ubound <- 1.55E+3
n_k <- 500
Examine_likelihood_M1(R0,lbound,ubound,n_k)
setwd("F:/EMSE/3A/BIG Data/probas/TP1/TP1_Students_2020/TP1_Students_2020")
setwd("F:/EMSE/3A/BIG Data/probas/TP1/TP1_Students_2020/TP1_Students_2020")
Examine_likelihood_M1(R0,lbound,ubound,n_k)
setwd("F:/EMSE/3A/BIG Data/probas/TP0_et_1")
mu <- 0     # moyenne
sigma <- 1  # écart-type = racine carrée de la variance
nb.tirages <- 100  # nombre de tirages aléatoires = taille échantillon simulé
# Utilisation du générateur de nombre normal rnorm : "r = random" et "norm = normal"
x.simu <- rnorm(n=nb.tirages, mean=mu, sd=sigma)
# Visualisation des données simulées
plot(1:nb.tirages, x.simu, xlab="Numéro de simulation", ylab="Simulations",
main="Simulations d'une loi normale")
abline(h=mu, lty=1, col="red", lwd=2)   # lty = line type (1 par défaut)
abline(h=1.96, lty=2, col="red", lwd=2) # lwd = line width (1 par défaut)
abline(h=-1.96, lty=2, col="red", lwd=2)
nb.tirages <- 10000
x.simu <- rnorm(n=nb.tirages, mean=mu, sd=sigma)
hist(x.simu, breaks=20, freq=FALSE, xlab="Valeurs simulées", ylab="Densité",
main="",ylim=c(0,0.45))
points(x.simu, rep(0,nb.tirages), pch='+', cex=0.5, col="blue") # cex = coeff. expansion
maxx = mu + 3.5*sigma
minx = mu - 3.5*sigma
x.grid <- seq(minx, maxx, 0.01)
fd <- dnorm(x.grid, mean=mu, sd=sigma) # dnorm pour densité normale : "d = density"
lines(x.grid, fd, col="red", lwd=2)
title("Histogramme et densité réelle")
probas <- c(0.025, 0.25, 0.5, 0.75, 0.975)
q <- qnorm(probas, mean=0, sd=1) # quantiles théoriques : "q = quantile"
print(round(q,2))
# Vérification à l'aide de la fonction de répartition F définie par:
# q -> p = P(X <= q) (cumulative distribution function ou cdf)
probas.q  <- pnorm(q, mean=0, sd=1) # cdf : "p = probability"
print(probas.q)
# A connaître probas à +/- sigma | 2*sigma | 3*sigma
#                          68%   | 95 %    | 99.7%
probas <- 2*pnorm(c(1,2,3), mean=0, sd=1) - 1
print(round(probas,3))
q4.hat <- quantile(x.simu, probs=c(0.25,0.5,0.75))
print(round(q4.hat,2))
q4.theo <- qnorm(probas, mean=mu, sd=sigma)
q4.theo <- mu + sigma*qnorm(c(0.25,0.5,0.75), mean=0, sd=1) # variante
print(round(q4.theo,2))
mu <- 1
sigma <- 3
nb.tirages <- 1000
x.simu <- rnorm(n=nb.tirages, mean=mu, sd=sigma) # simulation
probas <- seq(from=0.05, to=0.95, by=0.05)
q.theo <- qnorm(probas, mean=0, sd=1)
q.hat <- quantile(x.simu, probas)
plot(q.theo, q.hat, xlab="Quantiles théoriques N(0,1)", ylab="Quantiles expérimentaux")
abline(a=mu, b=sigma, col="red", lwd=2)
grid()
title("Droite de Henry")
nb.tirages <- 200
x.simu <- rnorm(n=nb.tirages, mean=0, sd=1)
y.simu <- rnorm(n=nb.tirages, mean=0, sd=1)
plot(x.simu, y.simu, type='p', pch='+', asp=1, xlab="x", ylab="y")
abline(h=0,lty=2)
abline(v=0,lty=2)
library(mixtools)
mu <- c(0,0) # Moyenne du vecteur aléatoire (X,Y)
sigma <- matrix(c(1, 0, 0, 1),nrow = 2) # Matrice de covariance du vecteur (X,Y)
# courbes d'iso-probabilité du vecteur (X,Y)
for (niv in 1:5){
ellipse(mu, sigma, alpha=.5/niv, col='red')
}
title("Courbes d'iso-probabilité (cas de l'indépendance)", cex.main=0.8)
sX <- 3
sY <- 1
nb.tirages <- 200
x.simu <- sX*rnorm(n=nb.tirages, mean=0, sd=1)
y.simu <- sY*rnorm(n=nb.tirages, mean=0, sd=1)
plot(x.simu, y.simu, type='p', pch='+', asp=1, xlab="x", ylab="y")
abline(h=0,lty=2)
abline(v=0,lty=2)
mu <- c(0,0) # Moyenne du vecteur aléatoire (X,Y)
sigma <- matrix(c(sX^2, 0, 0, sY^2),nrow = 2) # Matrice de covariance du vecteur (X,Y)
# courbes d'iso-probabilité du vecteur (X,Y)
for (niv in 1:5){
ellipse(mu, sigma, alpha=.5/niv, col='red')
}
title("Courbes d'iso-probabilité = ellipses", cex.main=0.8)
mu <- c(0,0) # Moyenne du vecteur aléatoire (X,Y)
sigma <- matrix(0, nrow=2, ncol=2)
sigma[1,1] <- sX^2*cos(theta)^2+sY^2*sin(theta)^2
sigma[2,2] <- sX^2*sin(theta)^2+sY^2*cos(theta)^2
sigma[1,2] <- (sX^2-sY^2)*cos(theta)*sin(theta)
sigma[2,1] <- sigma[1,2]
# courbes d'iso-probabilité du vecteur (X,Y)
for (niv in 1:5){
ellipse(mu, sigma, alpha=.5/niv, col='red')
}
abline(a=0, b=tan(theta), col='blue')
abline(a=0, b=-1/tan(theta), col='blue')
title("Courbes d'iso-probabilité = ellipses", cex.main=0.8)
# Corrélation linéaire en fonction de theta
theta <- seq(0, pi/2, 0.01)
varX <- sX^2*cos(theta)^2+sY^2*sin(theta)^2
varY <- sX^2*sin(theta)^2+sY^2*cos(theta)^2
covXY <- (sX^2-sY^2)*cos(theta)*sin(theta)
rho <- covXY/sqrt(varX*varY)
plot(theta, rho, 'l', main='Corrélation')
grid()
# Question 9
nb.tirages <- 200
u.simu <- rnorm(n=nb.tirages, mean=0, sd=1)
v.simu <- rnorm(n=nb.tirages, mean=0, sd=1)
sX <- 3
sY <- 1
theta <- pi/3
x.simu <- sX*cos(theta)*u.simu - sY*sin(theta)*v.simu
y.simu <- sX*sin(theta)*u.simu + sY*cos(theta)*v.simu
plot(x.simu, y.simu, type='p', pch='+', asp=1, xlab="x", ylab="y")
abline(h=0,lty=2)
abline(v=0,lty=2)
mu <- c(0,0) # Moyenne du vecteur aléatoire (X,Y)
sigma <- matrix(0, nrow=2, ncol=2)
sigma[1,1] <- sX^2*cos(theta)^2+sY^2*sin(theta)^2
sigma[2,2] <- sX^2*sin(theta)^2+sY^2*cos(theta)^2
sigma[1,2] <- (sX^2-sY^2)*cos(theta)*sin(theta)
sigma[2,1] <- sigma[1,2]
# courbes d'iso-probabilité du vecteur (X,Y)
for (niv in 1:5){
ellipse(mu, sigma, alpha=.5/niv, col='red')
}
abline(a=0, b=tan(theta), col='blue')
abline(a=0, b=-1/tan(theta), col='blue')
title("Courbes d'iso-probabilité = ellipses", cex.main=0.8)
theta <- seq(0, pi/2, 0.01)
varX <- sX^2*cos(theta)^2+sY^2*sin(theta)^2
varY <- sX^2*sin(theta)^2+sY^2*cos(theta)^2
covXY <- (sX^2-sY^2)*cos(theta)*sin(theta)
rho <- covXY/sqrt(varX*varY)
plot(theta, rho, 'l', main='Corrélation')
grid()
nb.tirages <- 200
u.simu <- rnorm(n=nb.tirages, mean=0, sd=1)
v.simu <- rnorm(n=nb.tirages, mean=0, sd=1)
a <- -1; b <- 1; c <- 0.5; d <- 1
x.simu <- a*u.simu + b*v.simu
y.simu <- c*u.simu + d*v.simu
plot(x.simu, y.simu, type='p', pch='+', asp=1, xlab="x", ylab="y")
abline(h=0,lty=1)
abline(v=0,lty=1)
mu <- c(0,0) # Moyenne du vecteur aléatoire (X,Y)
sigma <- matrix(0, nrow=2, ncol=2)
sigma[1,1] <- a^2 + b^2
sigma[2,2] <- c^2 + d^2
sigma[1,2] <- a*c + b*d
sigma[2,1] <- sigma[1,2]
# courbes d'iso-probabilité du vecteur (X,Y)
for (niv in 1:5){
ellipse(mu, sigma, alpha=.5/niv, col='red')
}
title("Courbes d'iso-probabilité et DMC", cex.main=0.8)
Vp <- eigen(sigma)$vectors
abline(a=0, b=-Vp[1,2]/Vp[2,2], col='red', lty=2, lwd=2)
abline(a=0, b=-Vp[1,1]/Vp[2,1], col='red', lty=2, lwd=2)
abline(a=0, b = sigma[1,2]/sqrt(sigma[1,1]*sigma[2,2]),
col="blue", lwd=2)
# courbes d'iso-probabilité du vecteur (X,Y)
for (niv in 1:5){
ellipse(mu, sigma, alpha=.5/niv, col='red')
}
title("Courbes d'iso-probabilité et DMC", cex.main=0.8)
# courbes d'iso-probabilité du vecteur (X,Y)
for (niv in 1:5){
ellipse(mu, sigma, alpha=.5/niv, col='red')
}
title("Courbes d'iso-probabilité et DMC", cex.main=0.8)
covXY <- (sX^2-sY^2)*cos(theta)*sin(theta)
nb.tirages <- 200
u.simu <- rnorm(n=nb.tirages, mean=0, sd=1)
v.simu <- rnorm(n=nb.tirages, mean=0, sd=1)
a <- -1; b <- 1; c <- 0.5; d <- 1
x.simu <- a*u.simu + b*v.simu
y.simu <- c*u.simu + d*v.simu
plot(x.simu, y.simu, type='p', pch='+', asp=1, xlab="x", ylab="y")
abline(h=0,lty=1)
abline(v=0,lty=1)
mu <- c(0,0) # Moyenne du vecteur aléatoire (X,Y)
sigma <- matrix(0, nrow=2, ncol=2)
sigma[1,1] <- a^2 + b^2
sigma[2,2] <- c^2 + d^2
sigma[1,2] <- a*c + b*d
sigma[2,1] <- sigma[1,2]
# courbes d'iso-probabilité du vecteur (X,Y)
for (niv in 1:5){
ellipse(mu, sigma, alpha=.5/niv, col='red')
}
title("Courbes d'iso-probabilité et DMC", cex.main=0.8)
Vp <- eigen(sigma)$vectors
View(Vp)
View(Vp)
print(eigen(sigma))
abline(a=0, b=-Vp[1,2]/Vp[2,2], col='red', lty=2, lwd=2)
abline(a=0, b=-Vp[1,1]/Vp[2,1], col='red', lty=2, lwd=2)
abline(a=0, b = sigma[1,2]/sqrt(sigma[1,1]*sigma[2,2]),
col="blue", lwd=2)
xx <- seq(-3,3,0.01)
pxx <- dnorm(xx, mean=0, sd=1) # densité de la loi N(0,1) calculée aux points xx
plot(xx, pxx,'l', col="red", lwd=2,xlab='x', ylab='f(x)',
main="Densité de la loi normale N(0,1)", cex.main=1)
grid()
abline(h=0,lty=2)
abline(v=0,lty=2)
n <- 12
p <- 0.5
xx <- seq(0,n,1)
pxx <- dbinom(xx,size=n,prob=p) # probabilités discrètes de la loi binomiale B(n,p)
xx <- seq(0,n,0.01)
plot(xx, dnorm(xx, mean=n*p, sd=sqrt(n*p*(1-p))), 'l', col="red", lwd=2,
ylab="densité", xlab="x")
grid()
abline(h=0, lty=2)
for (k in 0:n){
lines(c(k-0.5,k-0.5), c(0,pxx[k+1]), 'l')
lines(c(k-0.5,k+0.5), c(pxx[k+1],pxx[k+1]), 'l')
lines(c(k+0.5,k+0.5), c(0,pxx[k+1]), 'l')
}
axis(1, 0:n,0:n)
title('Loi binomiale B(n=12, p=0.5) et loi normale N(np, np(1-p)', cex.main=1)
xx <- seq(0,n,0.01)
plot(xx, dnorm(xx, mean=n*p, sd=sqrt(n*p*(1-p))), 'l', col="red", lwd=2,
ylab="densité", xlab="x")
grid()
abline(h=0, lty=2)
n <- 12
p <- 0.5
xx <- seq(0,n,1)
pxx <- dbinom(xx,size=n,prob=p) # probabilités discrètes de la loi binomiale B(n,p)
xx <- seq(0,n,0.01)
plot(xx, dnorm(xx, mean=n*p, sd=sqrt(n*p*(1-p))), 'l', col="red", lwd=2,
ylab="densité", xlab="x")
grid()
abline(h=0, lty=2)
for (k in 0:n){
lines(c(k-0.5,k-0.5), c(0,pxx[k+1]), 'l')
lines(c(k-0.5,k+0.5), c(pxx[k+1],pxx[k+1]), 'l')
lines(c(k+0.5,k+0.5), c(0,pxx[k+1]), 'l')
}
axis(1, 0:n,0:n)
title('Loi binomiale B(n=12, p=0.5) et loi normale N(np, np(1-p)', cex.main=1)
n <- 100
p <- 0.5
N <- 4000 # nombre de simulations de la loi binomiale
s <- rbinom(N, size=n,prob=p) # s = échantillon de taille N de la loi binomiale B(n,p)
z <- (s - n*p)/sqrt(n*p*(1-p)) # z = échantillon s après centrage et réduction
# Comparaison 1: histogramme de l'échantillon z et densité de la loi normale N(0,1)
hist(z, prob=TRUE, xlab="z", ylab = "",
main="Histogramme et densité N(0,1)", breaks=30, cex.main=1)
xx <- seq(-3.5,3.5,0.01)
lines(xx, dnorm(xx,mean=0,sd=1),'l',col="red",lwd=2)
# Comparaison 2: quantiles empiriques contre quantiles de la loi normale N(0,1)
qqnorm(z) # sur les données centrées-réduites
qqline(z, col="red", probs=c(0.1,0.9), lwd=2)
qqnorm(s) # sur les données brutes
qqline(s, col="red", probs=c(0.1,0.9), lwd=2)
n <- 100
p <- 0.5
N <- 4000 # nombre de simulations de la loi binomiale
s <- rbinom(N, size=n,prob=p) # s = échantillon de taille N de la loi binomiale B(n,p)
z <- (s - n*p)/sqrt(n*p*(1-p)) # z = échantillon s après centrage et réduction
# Comparaison 1: histogramme de l'échantillon z et densité de la loi normale N(0,1)
hist(z, prob=TRUE, xlab="z", ylab = "",
main="Histogramme et densité N(0,1)", breaks=30, cex.main=1)
xx <- seq(-3.5,3.5,0.01)
lines(xx, dnorm(xx,mean=0,sd=1),'l',col="red",lwd=2)
qqnorm(z) # sur les données centrées-réduites
qqline(z, col="red", probs=c(0.1,0.9), lwd=2)
qqnorm(s) # sur les données brutes
qqline(s, col="red", probs=c(0.1,0.9), lwd=2)
p0 <- 0.5 # probabilité de la classe 0
p1 <- 0.25 # probabilité de la classe 1
p2 <- 0.25 # probabilité de la classe 2
if (p0+p1+p2 != 1) print("Erreur : la somme des probabilités est différente de 1")
# Simulation de la loi trinomiale (loi multinomiale à 3 classes) - un exemple simple
N <- 1 # nombre de simulations de la loi trinomiale
n <- 100 # nombre d'épreuves = nombre de tirages d'une variable à 3 modalités
s <- rmultinom(N, size=n, prob=c(p0,p1,p2))
print(s)
help(rmultinom)
p0 <- 0.5 # probabilité de la classe 0
p1 <- 0.25 # probabilité de la classe 1
p2 <- 0.25 # probabilité de la classe 2
if (p0+p1+p2 != 1) print("Erreur : la somme des probabilités est différente de 1")
# Simulation de la loi trinomiale (loi multinomiale à 3 classes) - un exemple simple
N <- 1 # nombre de simulations de la loi trinomiale
n <- 100 # nombre d'épreuves = nombre de tirages d'une variable à 3 modalités
s <- rmultinom(N, size=n, prob=c(p0,p1,p2))
print(s)
apply(s, 2,"sum") # somme sur les colonnes
n0 <- s[1,] # échantillon loi B(n,p0) = loi du nombre N0 d'éléments dans la classe 0
n1 <- s[2,] # échantillon loi B(n,p1) = loi du nombre N1 d'éléments dans la classe 1
n2 <- s[3,] # échantillon loi B(n,p2) = loi du nombre N2 d'éléments dans la classe 2
# Question 1
p0 <- 0.1   # probabilité de la classe 0
p1 <- 0.5   # probabilité de la classe 1
p2 <- 0.4   # probabilité de la classe 2
n <- 500    # nombre d'épreuves = nombre de tirages d'une variable à 3 modalités
N <- 100    # nombre de simulations de la loi trinomiale
s <- rmultinom(N, size=n, prob=c(p0,p1,p2))
dim(s)
n1 <- s[2,] # échantillon loi B(n,p1) = loi du nombre N1 d'éléments dans la classe 1
n2 <- s[3,] # échantillon loi B(n,p2) = loi du nombre N2 d'éléments dans la classe 2
z <- matrix(0, nrow=2, ncol=N) # initialisation des variables centrées-réduites
z[1,] <- (n1 - n*p1)/sqrt(n*p1*(1-p1))
z[2,] <- (n2 - n*p2)/sqrt(n*p2*(1-p2))
# Question 2 : normalité de Z1 et Z2
qqnorm(z[1,]); qqline(z[1,], col="red", probs=c(0.1,0.9), lwd=2)
qqnorm(z[2,]); qqline(z[2,], col="red", probs=c(0.1,0.9), lwd=2)
plot(z[1,], z[2,], type='p', pch='+', asp=1,
xlab="z1", ylab="z2")
abline(h=0, lty=2)
abline(v=0, lty=2)
abline(a=0, b=rho, col="red", lwd=2)
rho.emp <- cor(z[1,], z[2,])
z <- matrix(0, nrow=2, ncol=N) # initialisation des variables centrées-réduites
z[1,] <- (n1 - n*p1)/sqrt(n*p1*(1-p1))
z[2,] <- (n2 - n*p2)/sqrt(n*p2*(1-p2))
# Question 2 : normalité de Z1 et Z2
qqnorm(z[1,]); qqline(z[1,], col="red", probs=c(0.1,0.9), lwd=2)
qqnorm(z[2,]); qqline(z[2,], col="red", probs=c(0.1,0.9), lwd=2)
# Question 3 : corrélation entre Z1 et Z2
plot(z[1,], z[2,], type='p', pch='+', asp=1,
xlab="z1", ylab="z2")
abline(h=0, lty=2)
abline(v=0, lty=2)
# Corrélation théorique
rho <- - p1*p2/sqrt(p1*(1-p1)*p2*(1-p2))
# Droite de régression théorique de Y2 sur Y1 : pente = rho
abline(a=0, b=rho, col="red", lwd=2)
# Corrélation empirique (estimée sur les données simulées)
rho.emp <- cor(z[1,], z[2,])
# Comparaison
cat(" Corrélation théorique : ", round(rho,3), "\n",
"Corrélation empirique : ", round(rho.emp,3), "\n")
help(rmultinom)
C1 <- (sqrt(2)/2)*(z[1,]+z[2,])
C2 <- (sqrt(2)/2)*(-z[1,]+z[2,])
# On intervertit les 2 nouveaux axes pour plus de
# lisibilité
plot(C2, C1, type='p', pch='+', asp=1,
xlab="C2", ylab="C1")
grid()
abline(h=0, lty=2)
abline(v=0, lty=2)
qqnorm(C1); qqline(C1,col="red", probs=c(0.1,0.9), lwd=2)
v1 <- var(C1)
cat("  Variance estimée de C1  : ", round(v1,3), "\n",
" Comparaison avec 1+rho  : ", round(1+rho,3))
qqnorm(C2); qqline(C2, col="red", probs=c(0.1,0.9), lwd=2)
v2 <- var(C2)
cat("  Variance estimée de C2  : ", round(v2,3), "\n",
" Comparaison avec 1-rho  : ", round(1-rho,3))
