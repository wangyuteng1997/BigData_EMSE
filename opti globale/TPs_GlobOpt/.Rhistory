seq <- which(suite <0.4)
Qt <- suite[seq]
volQt <- function(Qt){
result <- 1
for (t in Qt) {
result <- t*result
}
return(result)
}
n <- 10000
suite <- vanDerCorput(n)
seq <- which(suite <0.4)
Qt <- suite[seq]
VolQt <- VolQt(Qt)
VolQt <- volQt(Qt)
#On définit la discrépance comme suit
Discrepancy <- length(Qt)/length(suite)-area
n <- 10000
area <- 0.4
suite <- vanDerCorput(n)
seq <- which(suite <area)
Qt <- suite[seq]
VolQt <- volQt(Qt)
#On définit la discrépance comme suit
Discrepancy <- length(Qt)/length(suite)-area
#la discrépance
# le plan est entre [0,1] ici on prends Q(t) entre [0,0.4]
n <- seq(from=10000, to=100000, by=1)
n <- seq(from=10000, to=100000, by=1)
area <- 0.4
i <- 0
for (n in n) {
suite <- vanDerCorput(n)
seq <- which(suite <area)
Qt <- suite[seq]
#On définit la discrépance comme suit
Discrepancy[i] <- length(Qt)/length(suite)-area
i <- i+1
}
knitr::opts_chunk$set(echo = TRUE)
a <- 0.75
X <- c(-2,-1,4,5,7)
Y <- a+sin(X)
kgauss<-function(x,y,theta,sigma)
{
n<-length(x)
p<-length(y)
A<-matrix(0,nrow = n,ncol=p)
for(i in 1:n)
{
for (j in 1:p)
{
A[i,j]<-(sigma*sigma)*exp(-((abs(x[i]-x[j]))^2)/(2*theta*theta))
}
}
return(A)
}
n <- 100 # nombre de points de discretisation
xnew <- matrix(seq(from=-10, to=10, length=n),ncol=1)
K <- kgauss(X,X,theta = 1,sigma = 1)
h <- kgauss(xnew,X,theta = 1,sigma = 1)
# tapez votre code ici
View(h)
# tapez votre code ici
h_t <- t(h)
K_1 <- solve(K)
m <- h%*%K_1%*%Y
install.packages("GuessCompx")
help(GuessCompx)
# tapez votre code ici
library(GuessCompx)
help(GuessCompx)
# tapez votre code ici
library(GuessCompx)
# tapez votre code ici
help(dply)
help(CompEst)
# tapez votre code ici
h_t <- t(h)
K_1 <- solve(K)
m <- h%*%K_1%*%Y
moyenne <- function(){
m <- h%*%K_1%*%Y
}
# tapez votre code ici
library(GuessCompx)
CompEst(moyenne)
# tapez votre code ici
library(GuessCompx)
out = CompEst(d = n, f = moyenne, replicates=2, start.size=2, max.time = 1)
# tapez votre code ici
#
a <- h%*%K
# tapez votre code ici
#
a <- h%*%K
which(a<0)
# tapez votre code ici
#
a <- h%*%K
sum(a)
which(a<0) # pas poids négatifs
# tapez votre code ici
valeur=eigen(K,symmetric=T)
# tapez votre code ici
valeur=eigen(K,symmetric=T)
#ici tout valeur propre > 0
x<-matrix(rnorm(100),nrow=10)
View(x)
# tapez votre code ici
valeur=eigen(K,symmetric=T)
#ici tout valeur propre > 0
x<-matrix(rnorm(100),nrow=5)
# tapez votre code ici
valeur=eigen(K,symmetric=T)
#ici tout valeur propre > 0
x<-matrix(rnorm(25),nrow=5)
# tapez votre code ici
valeur=eigen(K,symmetric=T)
#ici tout valeur propre > 0
x<-matrix(rnorm(25),nrow=5)
# tapez votre code ici
valeur=eigen(K,symmetric=T)
#ici tout valeur propre > 0
z<-matrix(rnorm(25),nrow=5)
vecteur <- s(z)%*%K%*%z
# tapez votre code ici
valeur=eigen(K,symmetric=T)
#ici tout valeur propre > 0
z<-matrix(rnorm(25),nrow=5)
vecteur <- t(z)%*%K%*%z
View(vecteur)
# tapez votre code ici
valeur=eigen(K,symmetric=T)
#ici tout valeur propre > 0
#Montrer pour un vecteur z
z<-matrix(rnorm(25),nrow=5)
vecteur <- t(z)%*%K%*%z
prod(diag(chol(vecteur))^2)
# tapez votre code ici
valeur=eigen(K,symmetric=T)
#ici tout valeur propre > 0
#Montrer pour un vecteur z
z<-matrix(rnorm(25),nrow=5)
vecteur <- t(z)%*%K%*%z
print(prod(diag(chol(vecteur))^2))
# tapez votre code ici
# La covariance de Krigeage Simple：]
sigma <- 1
c <- sigma^2 - m
# tapez votre code ici
# La covariance de Krigeage Simple：]
sigma <- 1
c <- sigma^2 - m
# La variance de Krigeage
v <- diag(c)
help("diag")
# Majeure Science des Donn?es 2019-2020
# UP4 : exploitation de simulateurs num?riques
# Gaussian process regression - Kriging
# Script du TP ? compl?ter...
library(MASS) # fonction mvrnorm()
# Mouvement brownien
# Noyau brownien
kBrown <- function(x,y,param=NULL){
if(is.null(param)) param <-1
param*outer(c(x),c(y),"pmin")
}
kgauss<-function(x,y,theta,sigma)
{
n<-length(x)
p<-length(y)
A<-matrix(0,nrow = n,ncol=p)
for(i in 1:n)
{
for (j in 1:p)
{
A[i,j]<-(sigma*sigma)*exp(-((abs(x[i]-x[j]))^2)/(2*theta*theta))
}
}
return(A)
}
kcos<-function(x,y,theta,sigma)
{
n<-length(x)
A<-matrix(0,nrow = n,ncol=n)
for(i in 1:n)
{
for (j in 1:n)
{
A[i,j]<-(sigma*sigma)*cos((x[i]-x[j])/theta)
}
}
return(A)
}
# Exemple d'utilisation de la fonction kBrown
X <- c(0.1,0.5,0.9)
kXX <- kBrown(X,X); print(kXX)
x <- 0.8
kxX <- kBrown(x,X); print(kxX)
# Simulation du mouvement brownien standard B
ngrid <- 201 # nombre de points de discr?tisation
xgrid <- matrix(seq(from=0, to=1, length=ngrid),ncol=1)
Kxgrid <- kgauss(xgrid,xgrid,theta = 0.2,sigma = 1) #kBrown(xgrid,xgrid)
muB <- 0*xgrid # moyenne du processus B
varB <- diag(Kxgrid) # variance de B
# Simulation avec mvrnorm = multivariate random normal
# attention Sigma = matrice de covariance
yB <- mvrnorm(n=5,mu=muB,Sigma=Kxgrid)
yB <- t(yB) # simulations en colonne
matplot(xgrid, yB, type='l', xlab="Temps t", ylab="B(t)", ylim=c(-3,3),
main="Simulations du MB standard")
abline(h=0, lty=2)
lines(xgrid,1.96*sqrt(varB),lty=2,col="red")
lines(xgrid,-1.96*sqrt(varB),lty=2,col="red")
# Krigeage avec le noyau brownien
nt<-21
Xg<-matrix(seq(from=0, to=1, length=nt), ncol=1)
Yg<-Xg+sin(4*pi*Xg)
vect<-sample(1:21,5,replace=T)
X <- Xg[vect]#matrix(seq(from=0.1, to=0.9, length=n), ncol=1)
yX<- Yg[vect]#matrix(c(0.5, 0, 2.5, 3, 2), ncol=1)
plot(X, yX, xlab="x", xlim=c(0,1), ylim=c(-0.5,3.5),ylab="y",
main="f(x) connue en 6 points", cex.main=1)
points(0,0)
abline(h=0, lty=2)
abline(v=0, lty=2)
m <- 21
x <- matrix(seq(from=0, to=1, length=m),ncol=1)
kxx <- kgauss(x,x,0.2,2)
kxX <- kgauss(x,X,0.2,2)
kXX <- kgauss(X,X,0.2,2)
invkXX <- solve(kXX)
mu.krig <- kxX%*%invkXX%*%yX
K.krig <- kxx - kxX%*%invkXX%*%t(kxX)
#K.krig<-(K.krig)%*%t(K.krig)
y.krig <- mvrnorm(5,mu.krig,K.krig)
param <- 1
var.krig <- param*diag(K.krig)
upp95 <- mu.krig + 1.96*sqrt(pmax(0,var.krig))
low95 <- mu.krig - 1.96*sqrt(pmax(0,var.krig))
par(mar=c(4.5,5.1,1.5,1.5))
plot(x, mu.krig, type="n", xlab="x",ylab="f(x) ?", ylim=range(low95-0.5,upp95+0.5),cex.axis=1,cex.lab=1)
lightblue <- rgb(114/255,159/255,207/255,.3)
darkblue <- rgb(32/255,74/255,135/255,1)
darkbluetr <- rgb(32/255,74/255,135/255,.3)
polygon(c(x,rev(x)),c(upp95,rev(low95)),border=NA,col=lightblue)
lines(x,mu.krig,col=darkblue,lwd=3)
lines(x,low95,col=darkbluetr,lwd=2)
lines(x,upp95,col=darkbluetr,lwd=2)
points(X, yX, pch=4, cex=1, lwd=3, col="red")
abline(h=0, lty=2)
abline(v=0, lty=2)
lines(x, mu.krig, col="red",lwd=2)
for (simu in 1:5){
lines(x, y.krig[simu,]) #col=darkbluetr)
}
title(main="Krigeage avec le noyau brownien",cex.main=1)
---
title: "TP1 Krigeage"
author: "Didier Rullière"
date: "5 décembre 2020"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Note: il est recommandé de travailler avec RStudio. A l'ouverture de ce document R markdown (.Rmd), si les accents apparaissent mal, dans RStudio sélectionner File, Reopen with encoding puis utf8. Une fois le document réalisé, vous pouvez utiliser le bouton knit pour générer une sortie au format html.
# Exercice 1. Un exemple minimal de Krigeage Simple
Nous allons ici considérer un exemple très minimal, que nous allons conduire pas à pas, sans utiliser de packages dédiés, pour bien comprendre la méthode.
On considère ici une fonction de réponse, disons
$$f(x) = a + sin(x) $$
On prendra dans un premier temps $a=0.75$.
Cette fonction $f$ est supposée inconnue, mais on observe $n=5$ valeurs de cette fonction aux abscisses contenues dans le vecteur $X=(-2, -1, 4, 5, 7)$.
## Question 1a. Noyau de covariance
Nous allons chercer à interpoler les valeurs observées de la fonction au moyen de krigeage simple.
Pour cela, nous allons modéliser les réponses par un processus Gaussien $Y(.)$. On suppose dans un premier temps que la covariance entre les valeurs du processus est donnée par la fonction suivante:
$$Cov(Y(x),Y(x')) = k(x,x') = \sigma^2 \exp\left(-\frac{(x-x')^2}{2\theta^2}\right) $$
* Cette fonction ne dépend que de $x-x'$, quelle est la conséquence sur la nature du processus $Y$?
* Quel est le nom de cette fonction de covariance (noyau de covariance)?
* Rapidement, à quelle page cette fonction de covariance est-elle décrite dans le livre <http://www.gaussianprocess.org/gpml/chapters/RW.pdf>? Vous pourrez lire le détail plus tard, vous disposez désormais d'une référence très complète!
```{r}
# 2.nuyau gaussien
#insérer vos réponses sous forme de commentaires:
```
## Question 1b. Observations
Créer les inputs $X$ et le vecteur de réponses $Y=f(X)$ en ces abscisses.
```{r}
a <- 0.75
X <- c(-2,-1,4,5,7)
Y <- a+sin(X)
```
## Question 1c. Matrices de covariance
Nous allons chercher à prédire la fonction en des abscisses réparties régulièrement sur l'intervalle $[-10 , 10]$, par exemple en $q=100$ abscisses. Ces abscisses sont regroupées dans un vecteur colonne $x^{new}$.
Créer les abcisses $x_{new}$. En supposant $\theta=1$ et $\sigma^2=1$, créer deux matrices :
* la matrice $n \times n$ de covariances $K=(K_{ij})$ avec $K_{ij}=k(x_i,  x_j)$, où $x_i$ et $x_j$ sont des inputs observés. On note parfois cette matrice $K=k(X,X)$.
* le vecteur $n \times q$ de covariances $h=(h_{ij})$ avec $h_{ij}=k(x_i,  x^{new}_j)$. On note parfois cette matrice $h=k(X,x^{new})$.
Ne cherchez pas à faire un code optimal, mais simplement un code lisible.
```{r}
kgauss<-function(x,y,theta,sigma)
{
n<-length(x)
p<-length(y)
A<-matrix(0,nrow = n,ncol=p)
for(i in 1:n)
{
for (j in 1:p)
{
A[i,j]<-(sigma*sigma)*exp(-((abs(x[i]-x[j]))^2)/(2*theta*theta))
}
}
return(A)
}
n <- 100 # nombre de points de discretisation
xnew <- matrix(seq(from=-10, to=10, length=n),ncol=1)
K <- kgauss(X,X,theta = 1,sigma = 1)
h <- kgauss(xnew,X,theta = 1,sigma = 1)
# tapez votre code ici
```
Montrer pour un vecteur $\mathbf{z}$ de votre choix que $z^{\top} K z \ge 0$. Ce sera le cas pour tout $z$ si et seulement si les valeurs propres de $K$ sont $\ge 0$, montrer que ce sera bien le cas ici.
```{r}
# tapez votre code ici
valeur=eigen(K,symmetric=T)
#ici tout valeur propre > 0
#Montrer pour un vecteur z
z<-matrix(rnorm(25),nrow=5)
# Montrer pour un vecteur z de votre choix que z⊤Kz≥0
vecteur <- t(z)%*%K%*%zß
print(prod(diag(chol(vecteur))^2)) # >0
```
## Question 1d. Prédictions
La moyenne de Krigeage Simple aux abscisses $x^{new}$ est donné par la formule:
$$ m(x^{new}) = h^{\top} K^{-1} \cdot Y$$
tracer cette moyenne de Krigeage. Ajouter le nuage de points observés $(X,Y)$.
```{r}
# tapez votre code ici
h_t <- t(h)
K_1 <- solve(K)
m <- h%*%K_1%*%Y
```
Au sujet du calcul de la moyenne de Krigeage:
* Une fois les matrices K et h remplies, quelle est la complexité de ce calcul, en présence de $n$ observations?
* Chaque ligne de $\alpha = h^{\top} K^{-1}$ représente les poids affectés à chaque réponse dans la combinaison linéaire optimale. Ces poids se somment-ils à un ? y a-t-il des poids négatifs? Comment se comporte la prédiction loin des points observés? pourquoi?
```{r}
# tapez votre code ici
# complexité de ce calcul ：m :5
#pour h%*%K est O(n*m*m)
#pour h%*%K_1%*%Y est O(n*m*m) + O(n*m)   m est 5
#donc total est O(n)
a <- h%*%K
sum(a) # pas à un
which(a<0) # pas poids négatifs
```
## Question 1e. Intervalles de confiance
La covariance de Krigeage Simple aux abscisses $x^{new}$ est donné par la formule:
$$ c(x^{new}, x^{new}) = \sigma^2 - h^{\top} K^{-1} \cdot h$$
La variance de Krigeage est donnée par la diagonale de cette matrice
$$ v(x^{new}) = diag(c(x^{new}, x^{new}))$$
A l'aide de cette variance de Krigeage, ajouter des intervalles de confiances (sous une hypothèse Gaussienne) au graphique précédent.
```{r}
# tapez votre code ici
# La covariance de Krigeage Simple：]
sigma <- 1
c <- sigma^2 - m
# La variance de Krigeage
v <- diag(c)
# It can summarized by a mean function m(x) and 95% confidence intervals
# corresponding to the variance v(x) (under a distribution assumption).
```
# Question 2. Utilisation de paquets logiciels
Nous allons reprendre ici l'exemple élémentaire précédent, et retrouver les résultats obtenus à l'aide d'un paquet logiciel tout prêt *DiceKriging*, disponible sur le dépôt logiciel CRAN. Sauf mention contraire, toutes les variables utilisées seront celles de la question 1.
## Question 2a  Utilisation de DiceKrigring
Installer la librairie DiceKriging (dans R Studio, utiliser Tools, Install Packages). Charger cette librairie
```{r}
# tapez votre code ici
```
## Question 2b Modèle de Krigeage
Au moyen de la fonction *km* créer un modèle de Krigeage Simple, que vous stockerez dans une variable *monModele*.
(Pour schématiser *km* va calculer la matrice $K$ et son inverse, de façon à pouvoir faire ensuite plusieurs prédictions sans recalculer cette matrice.)
Vous aurez besoin d'utiliser les options suivantes:
* Pour le type de Krigeage,
* `formula = ~1` et `coef.trend = 0` pour du Krigeage Simple (on a un trend constant égal à zero)
* `formula = ~1` et `coef.trend = NULL` pour du Krigeage Ordinaire (on a un trend constant à estimer)
* `formula = ~Y~1+X` (ou `formula = ~Y~1+X+I(X^2))`et `coef.trend = NULL` pour du Krigeage Universel.
* Pour les observations: `design = ...`, `response = ... ` pour indiquer les inputs et output observés.
* Pour le noyau de covariance:
`covtype=...` (type de noyau), `coef.cov = ...` pour le(s) paramètre(s) $\theta$, `coef.var =` pour la variance $\sigma^2$
```{r}
# tapez votre code ici
```
Ensuite, établissez une prédiction aux points *x^{new}* au moyen de la fonction `predict` de DiceKriging.
Vous aurez à utiliser les paramètres suivants:
* `object=...` pour spécifier le modèle de Krigeage, vous indiquerez `monModele`.
* `newdata=...` pour spécifier les nouveaux inputs où l'on souhaite prédire
* `type=...` pour spécifier le prédicteur désiré, "SK" pour Simple Kriging, ou "UK" pour Ordinary et Universal.
* `checkNames=FALSE` si vous ne souhaitez pas vérifier les noms des variables dans les objets en entrée de type dataframe.
trouver l'option à utiliser pour calculer les variances (ou écart types) de Krigeage. Extraire moyenne et variance de Krigeage dans des variables $m_Dice$ et $v_Dice$.
```{r}
# tapez votre code ici
```
## Question 2c
Comparer les résultats obtenus avec ceux de l'exercice 1. Renvoyez un booléen qui renvoie TRUE ou FALSE selon que les résltats sont similaires ou non.
```{r}
# tapez votre code ici
```
_Remarque_: prenez l'habitude de tester ainsi vos résultats, à la façon de *tests unitaires*, cf. <https://en.wikipedia.org/wiki/Unit_testing> . Il est commun de vérifier manuellement le bon comportement de fonctions, puis malheureusement d'effacer ces vérifications. Le fait de préserver des tests automatisés, renvoyant des booléens faciles à agréger, permet de s'assurer du bon fonctionnement d'un programme au fur et à mesure qu'il évolue.
## Question 2d
Effectuez une nouvelle prédiction avec DiceKriging, en utilisant un Krigeage Ordinaire avec les mêmes paramètres. Tracer a prédiciton obtenue, quelle est la différence avec le Krigeage Simple?
```{r}
# tapez votre code ici
```
```{r}
# tapez votre code ici
```
_Remarque_: des indications et exemples sur le package DiceKriging sont aussi disponibles ici: <https://hal.archives-ouvertes.fr/hal-00495766/file/jss642.pdf>
# Question 3
Un industriel souhaite optimiser la conception d'aubes (de pales) de turbine. Il souhaite pour cela établir un plan d'expérience, puis un métamodèle qui lui permettra d'estimer la performance d'un profil d'aube donné.
A l'issue d'une première étude, deux paramètres de géométrie des aubes semblent cruciaux pour la performance globale de la turbine, ces deux paramètres ont été normalisés et prennent chacun des valeurs dans $[0,1]$. Pour la construction future du métamodèle, l'industriel souhaite utiliser un Krigeage simple. Les performances qu'il mesure semblent évoluer de façon très régulière, il souhaite donc opter pour un noyau de covariance Gaussien, de longueurs de corrélation (lengthscales) $\theta=0.3$ pour chacune des deux dimensions.
L'industriel envisage de procéder en deux étapes:
* Créer un plan d'expérience simple, construire des prototypes et effectuer des mesures précises de performance pour $n=20$ profils différents.
* Puis créer et tracer un métamodèle, à partir d'un Krigeage Simple des observations effectuées.
La réalisation des $n$ prototypes et essais devrait prendre un mois, il est donc important de ne pas faire d'essais trop similaires...
## 3a. Plan optimisé Kriging Based Design - grille d'évaluation
Créer une fonction pour évaluer numériquement le critère IMSE d'un plan donné.
Pour cela, on va tout d'abord créer une grille de points $x^{new}$ de taille 10000 x 2 par exemple, couvrant le carré $[0,1]^2$. Vous pourrez utiliser pour cela la fonction `expand.grid`.
```{r}
# tapez votre code ici
```
## 3b. Plan optimisé Kriging Based Design - critère emse
Par Krigeage Simple et pour un plan $X$, on en déduit alors la valeur de la variance de Krigeage sur chaque point de la grille $x^{new}$, une moyenne de ces grandeurs donnera le critère IMSE.
Tout d'abord, pour un plan X donné, la variance de Krigeage dépend-elle des réponses $Y$ observées? La minimisation d'un critère IMSE sera-t-elle affectée par la variance $\sigma^2$ de la réponse ?
```{r}
# tapez vos commentaires ici
```
Créer un plan $X$ de $n$ essais dans $[0,1]^2$, tirés de façon uniforme qui permettra de tester votre fonction.
Calculer par Krigeage simple, à l'aide de DiceKriging, la variance de Krigeage en chaque point $x^{new}$. Attention, vous aurez besoin d'un paramètre de portée (lengthscale $\theta$) par dimension. Quand tout fonctionne, encapsulez le tout dans une fonction IMSE, prenant en argument un plan X, et renvoyant le critère EMSE.
```{r}
# tapez votre code ici
```
## 3c. Plan optimisé 'Kriging Based Design' final
Répéter 1000 fois le tirage aléatoire d'un plan $X$ et le calcul de l'IMSE correspondant. Sauvegarder le meilleur et le pire plan obtenu pour ce critère. Nommez ces deux plans *Xbest* et *Xworse*, tracez ces plans.
Remarque: On pourrait bien sûr améliorer le meilleur plan en partant de plans plus optimisés (l'enjeu était ici de voir aussi de "mauvais" plans).
```{r}
# tapez votre code ici
```
## 3d. Le grand jour
Après un mois de travaux, de construction de turbines et de tests de performance, l'industriel est en mesure de donner la mesure de performance pour chacun des $n$ points du meilleur plan d'expérience *Xbest*.
Nous supposerons ici que cette performance nommée *Y* est le résultat de la fonction *branin* du package DiceKriging.
Calculer *Y* pour chaque point de *Xbest*, puis calculer la moyenne de Krigeage Simple en chacun des points de *xnew*. En vous inspirant de ce code <https://rdrr.io/cran/DiceKriging/man/branin.html> tracer les courbes de niveau de votre moyenne de Krigeage. On pourra remplacer `contour(x,y,z,40)` par `filled.contour(x,y,z)` pour un résultat plus visuel.
```{r}
# tapez votre code ici
```
# tapez votre code ici
# La covariance de Krigeage Simple：]
sigma <- 1
c <- sigma^2 - m
# La variance de Krigeage
v <- diag(c)
# It can summarized by a mean function m(x) and 95% confidence intervals
# corresponding to the variance v(x) (under a distribution assumption).
plot(xnew,m)
# tapez votre code ici
# La covariance de Krigeage Simple：]
sigma <- 1
c <- sigma^2 - m
# La variance de Krigeage
v <- diag(c)
# It can summarized by a mean function m(x) and 95% confidence intervals
# corresponding to the variance v(x) (under a distribution assumption).
plot(xnew,m)
abline(xnew,c)
# tapez votre code ici
# La covariance de Krigeage Simple：]
sigma <- 1
c <- sigma^2 - m
# La variance de Krigeage
v <- diag(c)
# It can summarized by a mean function m(x) and 95% confidence intervals
# corresponding to the variance v(x) (under a distribution assumption).
plot(xnew,m)
abline(xnew,c)
# tapez votre code ici
# La covariance de Krigeage Simple：]
sigma <- 1
c <- sigma^2 - m
# La variance de Krigeage
v <- diag(c)
# It can summarized by a mean function m(x) and 95% confidence intervals
# corresponding to the variance v(x) (under a distribution assumption).
plot(xnew,m)
abline(xnew,c)
# tapez votre code ici
# La covariance de Krigeage Simple：]
sigma <- 1
c <- sigma^2 - m
# La variance de Krigeage
v <- diag(c)
# It can summarized by a mean function m(x) and 95% confidence intervals
# corresponding to the variance v(x) (under a distribution assumption).
plot(xnew,m)
points(xnew,c)
setwd("~/Desktop/bigdata/opti globale")
setwd("~/Desktop/bigdata/opti globale/TPs_GlobOpt")
# tapez votre code ici
# La covariance de Krigeage Simple：]
sigma <- 1
c <- sigma^2 - m
# La variance de Krigeage
v <- diag(c)
# It can summarized by a mean function m(x) and 95% confidence intervals
# corresponding to the variance v(x) (under a distribution assumption).
plot(xnew,m)
